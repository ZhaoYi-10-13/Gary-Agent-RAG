# RAG AI Agent Backend

A minimal, production-ready FastAPI backend demonstrating Retrieval-Augmented Generation (RAG) with vector similarity search. Built for educational purposes and easy frontend integration.

## ğŸ¯ Features
	â€¢	FastAPI backend with automatic API documentation
	â€¢	Supabase integration with pgvector for vector similarity search
	â€¢	Multi-AI Provider support (Aliyun, OpenAI & Anthropic)
	â€¢	Aliyun Qwen as the recommended default provider
	â€¢	Vector embeddings with semantic search
	â€¢	Citation-based answers with source tracking
	â€¢	Docker containerization for easy deployment

## ğŸ—ï¸ Architecture

Gary-Agent-RAG/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/           # Infrastructure (config, database)
â”‚   â”œâ”€â”€ models/         # Pydantic data models
â”‚   â”œâ”€â”€ services/       # Business logic (RAG, embeddings)
â”‚   â””â”€â”€ main.py         # FastAPI application
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ init_supabase.sql  # Database initialization script
â””â”€â”€ requirements.txt

ğŸš€ Quick Start Guide

Complete setup from clone to asking questions in ~10 minutes

â¸»

Prerequisites
	â€¢	Python 3.11+
	â€¢	Supabase account
	â€¢	Aliyun API key 
	â€¢	(Optional) OpenAI / Anthropic API key

â¸»

Step 1: Clone and Install Dependencies

# Clone the repository
git clone https://github.com/ZhaoYi-10-13/Gary-Agent-RAG.git
cd Gary-Agent-RAG

# Create virtual environment
python3.11 -m venv venv_gary_rag
source venv_gary_rag/bin/activate  # On Windows: venv_gary_rag\Scripts\activate

# Install dependencies
pip install -r requirements.txt


â¸»

Step 2: Get API Keys (5 minutes)

Supabase Setup:
	1.	Go to supabase.com and create a new project
	2.	Wait for project to be ready (~2 minutes)
	3.	Go to Settings â†’ API and copy:
	â€¢	Project URL (e.g., https://abc123.supabase.co)
	â€¢	Anon public key (starts with eyJ...)
	â€¢	Service role secret key (starts with eyJ...)

Aliyun Setup (recommended):
	1.	Go to Aliyun Bailian Console
	2.	Login and get the API for large models (LLM API Key)
	3.	Copy your ALIYUN_API_KEY

(Optional) OpenAI / Anthropic Setup
	â€¢	You can also configure OPENAI_API_KEY or ANTHROPIC_API_KEY as backup providers.

â¸»

Step 3: Configure Environment

# Copy environment template
cp .env.example .env

# Edit with your real API keys
nano .env  # or use your preferred editor

Update .env with your values:

# -------- Supabase --------
SUPABASE_URL=https://your-project-ref.supabase.co
SUPABASE_ANON_KEY=your_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# -------- AI Provider --------
# é»˜è®¤èµ°é˜¿é‡Œäº‘é€šä¹‰åƒé—®
AI_PROVIDER=aliyun

# é˜¿é‡Œäº‘é€šä¹‰åƒé—®é…ç½®
ALIYUN_API_KEY=sk-your_aliyun_key_here
ALIYUN_CHAT_MODEL=qwen-plus
ALIYUN_EMBED_MODEL=text-embedding-v4

# å¯é€‰ï¼šOpenAI
OPENAI_API_KEY=sk-your_openai_key_here
OPENAI_CHAT_MODEL=gpt-4o
OPENAI_EMBED_MODEL=text-embedding-3-large

# å¯é€‰ï¼šAnthropic
ANTHROPIC_API_KEY=your_anthropic_key_here
ANTHROPIC_CHAT_MODEL=claude-3-5-sonnet-20241022

# -------- App Config --------
ENVIRONMENT=development
LOG_LEVEL=INFO


â¸»

Step 4: Initialize Database (2 minutes)
	1.	Open Supabase Dashboard â†’ SQL Editor
	2.	Click â€œNew queryâ€
	3.	Copy entire contents of sql/init_supabase.sql
	4.	Paste and click â€œRunâ€

âœ… This creates everything needed:
	â€¢	pgvector extension
	â€¢	rag_chunks table (with VECTOR(1024) per your config)
	â€¢	Performance indexes
	â€¢	Vector search functions
	â€¢	RLS policies for future auth

â¸»

Step 5: Test Setup

# Test your complete setup
python test_setup.py

This verifies:
	â€¢	âœ… Dependencies installed
	â€¢	âœ… API keys configured
	â€¢	âœ… Database connected
	â€¢	âœ… Schema initialized
	â€¢	âœ… RAG pipeline working

â¸»

### Step 6: Start the Server

```bash
uvicorn main:app --reload --port 8000
uvicorn main:app --host 0.0.0.0 --port 80 # For Aliyun HTTP Service
```

The API will be available at:
- **API**: http://localhost:8000
- **Interactive Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ“š API Usage

### Health Check
```bash
curl http://localhost:8000/healthz
```

### Seed Knowledge Base
```bash
# Seed with default documents
curl -X POST http://localhost:8000/seed

# Or seed with custom documents
curl -X POST http://localhost:8000/seed \
  -H "Content-Type: application/json" \
  -d '{
    "docs": [
      {
        "chunk_id": "policy_returns_v1#window",
        "source": "https://help.example.com/returns",
        "text": "You can return unworn items within 30 days of purchase..."
      }
    ]
  }'
```

### Ask Questions (RAG)
```bash
curl -X POST http://localhost:8000/answer \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Can I return shoes after 30 days?",
    "top_k": 6
  }'
```

**Example Response:**
```json
{
  "text": "Based on our return policy, you can return unworn shoes within 30 days of purchase [policy_returns_v1#window]. Items must be in original condition...",
  "citations": ["policy_returns_v1#window", "policy_returns_v1#conditions"],
  "debug": {
    "top_doc_ids": ["policy_returns_v1#window", "policy_returns_v1#conditions"],
    "latency_ms": 1250
  }
}
```

## ğŸ”§ Configuration Options

### AI Providers

**OpenAI (Recommended)**
```env
AI_PROVIDER=openai
OPENAI_API_KEY=your_key
OPENAI_EMBED_MODEL=text-embedding-3-small  # 1536 dimensions
OPENAI_CHAT_MODEL=gpt-4o-mini
```

**Anthropic Claude**
```env
AI_PROVIDER=anthropic
ANTHROPIC_API_KEY=your_key
ANTHROPIC_CHAT_MODEL=claude-3-haiku-20240307

# Note: Still need OpenAI key for embeddings
OPENAI_API_KEY=your_openai_key
```

### RAG Parameters

Adjust in `app/core/config.py`:
- `chunk_size`: Token limit per chunk (default: 400)
- `chunk_overlap`: Overlap between chunks (default: 60 tokens)
- `default_top_k`: Number of chunks to retrieve (default: 6)
- `temperature`: LLM creativity (default: 0.1)

## ğŸ³ Docker Deployment

```bash
# Build image
docker build -t Gary-Agent-RAG .

# Run container
docker run -p 8080:8080 --env-file .env yt-rag
```
